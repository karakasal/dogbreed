{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "\n",
    "df_dog = pd.read_csv(\"assets\\labels.csv\")\n",
    "df_dog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "len(os.listdir(\"assets\\\\train\\\\\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dog[\"breed\"].value_counts().median(), df_dog[\"breed\"].value_counts()[:20].plot(kind=\"bar\", figsize=(10,4), xlabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"assets\\\\train\\\\\" + fname + \".jpg\" for fname in df_dog[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = np.array(df_dog[\"breed\"])\n",
    "len(labels) == len(df_dog[\"breed\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_breeds = np.unique(labels)\n",
    "labels_bool = [label == unique_breeds for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filenames\n",
    "y = labels_bool\n",
    "\n",
    "IMAGES_NUM = 1000\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:IMAGES_NUM], y[:IMAGES_NUM], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "\n",
    "imread(filenames[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(filenames[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "  image = tf.io.read_file(image_path) \n",
    "  image = tf.image.decode_jpeg(image, channels=3) \n",
    "  image = tf.image.convert_image_dtype(image, tf.float32) \n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_label(path, label):\n",
    "    img = process_image(path)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_batches(X, y=None, batch_size=BATCH_SIZE, validation_data=False, test_data=False):\n",
    "    if test_data:\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) \n",
    "        data_batch = data.map(process_image).batch(batch_size=BATCH_SIZE) \n",
    "        return data_batch        \n",
    "    elif validation_data:\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data_batch = data.map(get_img_label).batch(batch_size=BATCH_SIZE)\n",
    "        return data_batch\n",
    "    else:\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data = data.shuffle(buffer_size=len(X)) \n",
    "        data = data.map(get_img_label) \n",
    "        data_batch = data.batch(batch_size=BATCH_SIZE)\n",
    "        return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = create_batches(X_train, y_train)\n",
    "validation_data = create_batches(X_val, y_val, validation_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.element_spec, validation_data.element_spec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, labels):\n",
    "    plt.figure(figsize=(8,10))\n",
    "    for i in range(25):\n",
    "        ax = plt.subplot(5, 5, i+1) \n",
    "        ax.tick_params(axis='both', labelsize=0)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(unique_breeds[labels[i].argmax()], fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(training_data.as_numpy_iterator()) \n",
    "\n",
    "show_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels = next(validation_data.as_numpy_iterator())\n",
    "\n",
    "show_images(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] \n",
    "\n",
    "OUTPUT_SHAPE = len(unique_breeds) \n",
    "\n",
    "MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_keras as tfk\n",
    "\n",
    "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
    "    model = tfk.Sequential([\n",
    "        hub.KerasLayer(MODEL_URL), \n",
    "        tfk.layers.Dense(units=OUTPUT_SHAPE, activation=\"softmax\") \n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tfk.losses.CategoricalCrossentropy(), \n",
    "        optimizer=tfk.optimizers.Adam(), \n",
    "        metrics=[\"accuracy\"] \n",
    "    )\n",
    "\n",
    "    model.build([None, 224, 224, 3]) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_cb():\n",
    "    log_dir = os.path.join('assets\\\\logs', datetime.datetime.now().strftime('%Y%m%d-%H%M%S')) \n",
    "    return tfk.callbacks.TensorBoard(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tfk.callbacks.EarlyStopping('val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model = create_model()\n",
    "    tensorboard_cb = create_tensorboard_cb()\n",
    "    model.fit(x=training_data, epochs=NUM_EPOCHS, validation_data=validation_data, validation_freq=1, callbacks=[tensorboard_cb, early_stopping]) # validation_freq= checks validation metrics every epoch.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir assets/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_data, verbose=1)\n",
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42\n",
    "print(np.max(predictions[index])) \n",
    "print(np.sum(predictions[index]))\n",
    "print(np.argmax(predictions[index])) \n",
    "print(unique_breeds[np.argmax(predictions[index])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label(prediction_probilities):\n",
    "    return unique_breeds[np.argmax(prediction_probilities)]\n",
    "\n",
    "pred_label = get_pred_label(predictions[0])\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_un = []\n",
    "labels_un = []\n",
    "\n",
    "for image, label in validation_data.unbatch().as_numpy_iterator():\n",
    "    images_un.append(image)\n",
    "    labels_un.append(label)\n",
    "\n",
    "labels_un[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbatch_images(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image, label in dataset.unbatch().as_numpy_iterator():\n",
    "        images.append(image)\n",
    "        labels.append(unique_breeds[np.argmax(label)])\n",
    "    return images, labels\n",
    "\n",
    "val_images, val_labels = unbatch_images(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(pred_probilities, labels, images, n=1):\n",
    "    pred_prob, true_label, image = pred_probilities[n], labels[n], images[n]\n",
    "\n",
    "    pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if pred_label == true_label:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    plt.title(f\"{pred_label} {np.max(pred_prob)*100:2.0f}%\", color=color, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(predictions, val_labels, val_images,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_top(pred_probilities, labels, n=1):\n",
    "    pred_prob, true_label = pred_probilities[n], labels[n]\n",
    "    pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "    top_10_indexes = pred_prob.argsort()[-10:][::-1]\n",
    "    top_10_values = pred_prob[top_10_indexes]\n",
    "    top_10_labels = unique_breeds[top_10_indexes]\n",
    "\n",
    "    top_plot = plt.bar(np.arange(len(top_10_labels)), top_10_values, color=\"grey\")\n",
    "\n",
    "    plt.xticks(np.arange(len(top_10_labels)), top_10_labels, rotation=\"vertical\", fontsize=8)\n",
    "\n",
    "    if np.isin(true_label, top_10_labels):\n",
    "        top_plot[np.argmax(top_10_labels == true_label)].set_color(\"green\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_top(predictions, val_labels, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_multiply = 10\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(6*num_rows, 6*num_cols))\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_pred(predictions, val_labels, val_images, i+i_multiply)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_pred_top(predictions, val_labels, i+i_multiply)\n",
    "plt.tight_layout(h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix=None):\n",
    "    modeldir = os.path.join('assets\\\\models', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    model_path = modeldir + \"-\" + suffix + \".h5\"\n",
    "    model.save(model_path)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = tfk.models.load_model(model_path, custom_objects={\"KerasLayer\":hub.KerasLayer}) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, suffix=\"1000-images-mobilnetv2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_1000 = load_model(\"assets\\\\models\\\\1000-images-mobilnetv2-Adam.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_1000.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = create_batches(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_cb = create_tensorboard_cb()\n",
    "full_model_earlystop = tfk.callbacks.EarlyStopping(\"accuracy\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.fit(full_data, epochs=NUM_EPOCHS, callbacks=[full_model_cb, full_model_earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, suffix=\"full-images-mobilnetv2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_full = load_model('assets\\\\models\\\\full-images-mobilnetv2-Adam.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"assets\\\\test\\\\\"\n",
    "filenames_test = [test_path + fname for fname in os.listdir(test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_batches(filenames_test, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = load_model_full.predict(test_data, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"assets\\\\predictions.csv\", predictions_test, delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(\"assets\\\\predictions.csv\", delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns=[\"id\"] + list(unique_breeds)) \n",
    "\n",
    "df_test[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
    "df_test[list(unique_breeds)] = predictions_test\n",
    "\n",
    "df_test.to_csv(\"assets\\\\predictions_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(pred_probilities, images, n=0):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.subplot\n",
    "    plt.imshow(plt.imread(images[n]))\n",
    "    plt.title(f\"{unique_breeds[np.argmax(pred_probilities[n])]} {np.max(pred_probilities[n])*100:2.0f}%\", \n",
    "                fontsize=10, y=1, pad=-14, backgroundcolor=\"yellow\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(predictions_test, filenames_test, 3232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_path = \"assets\\\\custom\\\\\"\n",
    "filenames_custom = [custom_path + fname for fname in os.listdir(custom_path)]\n",
    "custom_data = create_batches(filenames_custom, test_data=True)\n",
    "predictions_custom = load_model_full.predict(custom_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_custom(pred_probilities, images, n=0, folder=False):\n",
    "    '''\n",
    "    Folder=True if you want to use all images in the folder, else you can use n=number.\n",
    "    '''\n",
    "    if folder:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for n, image in enumerate(images):\n",
    "            plt.subplot(1, len(images), n+1)\n",
    "            plt.imshow(plt.imread(image))\n",
    "            plt.title(f\"{unique_breeds[np.argmax(pred_probilities[n])]} {np.max(pred_probilities[n])*100:2.0f}%\", \n",
    "                        fontsize=8, y=1, pad=-14, backgroundcolor=\"yellow\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([]);\n",
    "    else:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(plt.imread(images[n]))\n",
    "        plt.title(f\"{unique_breeds[np.argmax(pred_probilities[n])]} {np.max(pred_probilities[n])*100:2.0f}%\", \n",
    "                    fontsize=10, y=1, pad=-14, backgroundcolor=\"yellow\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image_custom(predictions_custom, filenames_custom, folder=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
